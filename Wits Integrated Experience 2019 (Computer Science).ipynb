{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''\n",
    "<style>\n",
    ".output_wrapper button.btn.btn-default,\n",
    ".output_wrapper .ui-dialog-titlebar {\n",
    "  display: none;\n",
    "}\n",
    "</style>\n",
    "''')\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this activity, we'll be using satellite imagery to automatically detect objects in the ocean. \n",
    "\n",
    "In order to do this, we need to develop a system that will detect water in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colour Selection\n",
    "\n",
    "Our satellite images are colour images. All colour images consist of three components: red, green and blue. The first step is to select which colours (or ratio of colours) we want to work with.\n",
    "\n",
    "Click on the buttons below to select which colours you want. The image on the left is the original image, while the one on the right is the colour component you selected (note that the individual colour components render in greyscale!) \n",
    "\n",
    "Think about the three colours and how they relate to land and water. We want an image that will separate the water from the land as best as possible. But how do we know which one is best?\n",
    "\n",
    "The histogram graph below shows the frequency of the pixel brightness in the new image. **The best choices will result in a graph with two peaks (a bimodal graph), which correspond to land and water respectively!**   \n",
    "\n",
    "Once you've made your choice, move on to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "from skimage import color\n",
    "from IPython.display import HTML\n",
    "\n",
    "global image_rgb\n",
    "global image_hsv\n",
    "global image\n",
    "global image_cleaned\n",
    "global threshold_value\n",
    "global choice\n",
    "global big_threshold\n",
    "global closing_size\n",
    "\n",
    "closing_size = 20\n",
    "big_threshold = 500001\n",
    "choice = \"All RGB Bands\"\n",
    "threshold_value = 0\n",
    "image_rgb = io.imread('34b2f95c3.jpg')\n",
    "image_hsv = color.convert_colorspace(image_rgb, 'RGB', 'HSV')\n",
    "image = image_rgb\n",
    "training_years = range(1984, 2008)\n",
    "testing_years = range(2008, 2030) \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    " \n",
    "def _select_bands(image_rgb, choice):\n",
    "    epsilon = 1\n",
    "    if choice == \"All RGB Bands\":\n",
    "        image = color.rgb2grey(image_rgb) * 255\n",
    "    elif choice == \"Red Band\":\n",
    "        image = image_rgb[:, :, 0] * 255\n",
    "    elif choice == \"Green Band\":\n",
    "        image = image_rgb[:, :, 1] * 255\n",
    "    elif choice == \"Blue Band\":\n",
    "        image = image_rgb[:, :, 2] * 255\n",
    "    elif choice == \"All HSV Bands\":\n",
    "        image = color.rgb2grey(image_rgb) * 255\n",
    "    elif choice == \"Hue\":\n",
    "        image = image_rgb[:, :, 0] * 255\n",
    "    elif choice == \"Saturation\":\n",
    "        image = image_rgb[:, :, 1] * 255\n",
    "    elif choice == \"Value\":\n",
    "        image = image_rgb[:, :, 2] * 255\n",
    "    elif choice == \"Red-Green Ratio\":\n",
    "        image = np.log(image_rgb[:, :, 0] / (image_rgb[:, :, 1] + epsilon))\n",
    "        image = image / image.max() * 255   \n",
    "    elif choice == \"Red-Blue Ratio\":\n",
    "        image = image_rgb[:, :, 0] / (image_rgb[:, :, 2] + epsilon)\n",
    "        image = image / image.max() * 255   \n",
    "    elif choice == \"Green-Red Ratio\":\n",
    "        image = image_rgb[:, :, 1] / (image_rgb[:, :, 0] + epsilon)\n",
    "        image = image / image.max() * 255   \n",
    "    elif choice == \"Green-Blue Ratio\":\n",
    "        image = image_rgb[:, :, 1] / (image_rgb[:, :, 2] + epsilon)\n",
    "        image = image / image.max() * 255   \n",
    "    elif choice == \"Blue-Red Ratio\":\n",
    "        image = image_rgb[:, :, 2] / (image_rgb[:, :, 0] + epsilon)\n",
    "        image = image / image.max() * 255   \n",
    "    elif choice == \"Blue-Green Ratio\":\n",
    "        image = image_rgb[:, :, 2] / (image_rgb[:, :, 1] + epsilon)\n",
    "        image = image / image.max() * 255   \n",
    "    else:\n",
    "        raise ValueError\n",
    "    return image\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def segment_image(image_rgb, spectrum, threshold):\n",
    "    \"\"\"\n",
    "    Return the segmented image and area\n",
    "    \"\"\"\n",
    "    im = _select_bands(image_rgb, spectrum)\n",
    "    clean_im = morphology.remove_small_objects((im < threshold), 50)\n",
    "    segmentation = ndi.binary_fill_holes(clean_im)\n",
    "    labeled_image, _ = ndi.label(segmentation)\n",
    "    image_label_overlay = label2rgb(labeled_image, image=clean_im)\n",
    "    plt.imshow(im_rgb, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    plt.contour(segmentation, [0.5], linewidths=1.2, colors='r')\n",
    "    return plt, image_label_overlay[:,:,1].sum()\n",
    "\n",
    "\n",
    "def _calculate_area(clean_im):\n",
    "    segmentation = ndi.binary_fill_holes(clean_im)\n",
    "    labeled_image, _ = ndi.label(segmentation)\n",
    "    image_label_overlay = label2rgb(labeled_image, image=clean_im)\n",
    "    return image_label_overlay[:,:,1].sum()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T14:54:52.965362Z",
     "start_time": "2018-02-19T14:54:52.912496Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_bands(c):\n",
    "    \n",
    "    global image\n",
    "    global image_rgb\n",
    "    global choice\n",
    "    choice = c\n",
    "    image = _select_bands(image_rgb, c)\n",
    "    \n",
    "\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax1 = fig.add_subplot(2,2,1)\n",
    "    ax1.set_title(\"Original Image\")\n",
    "    ax1.imshow(image_rgb, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    ax2 = fig.add_subplot(2,2,2)\n",
    "    ax2.set_title(\"New Image\")\n",
    "    ax2.imshow(image, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    ax3 = fig.add_subplot(2,2,3)\n",
    "    hist = np.histogram(image, bins=np.arange(0, 256))\n",
    "    ax3.set_title(\"Histogram\")\n",
    "   \n",
    "    plt.plot(hist[1][:-1], hist[0], lw=2)\n",
    "    \n",
    "    \n",
    "    #plt.imshow(image_rgb, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    #plt.show()\n",
    "    #plt.imshow()\n",
    "    #plt.show()\n",
    "    ##hist = np.histogram(image, bins=np.arange(0, 256))\n",
    "    #plt.plot(hist[1][:-1], hist[0], lw=2)\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "buttons = widgets.ToggleButtons(\n",
    "    #options=['All Bands', 'Red Band', 'Green Band', 'Blue Band', 'Red-Green Ratio', 'Red-Blue Ratio', 'Green-Red Ratio', 'Green-Blue Ratio','Blue-Red Ratio', 'Blue-Green Ratio'],\n",
    "    options=['All RGB Bands', 'Red Band', 'Green Band', 'Blue Band'],\n",
    "    description='Colours:',\n",
    "    disabled=False,\n",
    "    selected=2,\n",
    "    button_style='',\n",
    ")\n",
    "\n",
    "interact(select_bands, c=buttons);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding\n",
    "\n",
    "We now pick which sections of the image are part of the lake, and which are part of the land. Drag the slider to select a value. All pixels with values greater than the threshold will be considered as the lake. Everything else is the land.\n",
    "\n",
    "**Use the histogram above to select the threshold by picking a value in between the two peaks!**\n",
    "\n",
    "Try pick the value so the image looks like the shape of the lake (remember that the lake has two islands!). Once you're satisfied, move to the next step. If the thresholding doesn't result in a lake-shaped image, you may have to pick different colours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T14:56:22.213479Z",
     "start_time": "2018-02-19T14:56:21.823732Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def threshold(val):\n",
    "    global threshold_value\n",
    "    threshold_value = val\n",
    "    \n",
    "    fig = plt.figure(figsize=(9, 9))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.set_title(\"Image after Thresholding\")\n",
    "\n",
    "    ax.imshow(image < val, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    \n",
    "    #plt.imshow(image > val, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #plt.show()\n",
    "    #plt.tight_layout()\n",
    "\n",
    "threshold_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=255,\n",
    "    step=1,\n",
    "    description='Threshold:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "interact(threshold, val=threshold_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colour Spaces\n",
    "\n",
    "Sometimes the RGB colour space doesn't represent the colours in an intuitive way, and it becomes difficult to separate out the objects. We can see from the images above, that regardless of which channel and threshold you pick there will be lots of noise around the objects that we're trying to detect.\n",
    "\n",
    "Rather than representing images using the additive primary colours (Red-Green-Blue), we can use a different representation called HSV (Hue Saturation Value). The Hue refers to the colour, the saturation refers to the \"greyness\" and the value refers to the brightness.\n",
    "\n",
    "<a href=\"https://commons.wikimedia.org/wiki/File:HSV_color_solid_cylinder.png\"><img src=\"hsv1.png\" style=\"width: 400px;\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def select_bands_hsv(c):\n",
    "    \n",
    "    global image\n",
    "    global image_rgb\n",
    "    global image_hsv\n",
    "    global choice\n",
    "    choice = c\n",
    "    image = _select_bands(image_hsv, c)\n",
    "    \n",
    "\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax1 = fig.add_subplot(2,2,1)\n",
    "    ax1.set_title(\"Original Image\")\n",
    "    ax1.imshow(image_rgb, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    ax2 = fig.add_subplot(2,2,2)\n",
    "    ax2.set_title(\"New Image\")\n",
    "    ax2.imshow(image, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    ax3 = fig.add_subplot(2,2,3)\n",
    "    hist = np.histogram(image, bins=np.arange(0, 256))\n",
    "    ax3.set_title(\"Histogram\")\n",
    "    ax3.set_ylim(0,2500)\n",
    "    plt.plot(hist[1][:-1], hist[0], lw=2)\n",
    "    \n",
    "    \n",
    "    #plt.imshow(image_rgb, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    #plt.show()\n",
    "    #plt.imshow()\n",
    "    #plt.show()\n",
    "    ##hist = np.histogram(image, bins=np.arange(0, 256))\n",
    "    #plt.plot(hist[1][:-1], hist[0], lw=2)\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "buttons = widgets.ToggleButtons(\n",
    "    #options=['All Bands', 'Red Band', 'Green Band', 'Blue Band', 'Red-Green Ratio', 'Red-Blue Ratio', 'Green-Red Ratio', 'Green-Blue Ratio','Blue-Red Ratio', 'Blue-Green Ratio'],\n",
    "    options=['All HSV Bands', 'Hue', 'Saturation', 'Value'],\n",
    "    description='Colours:',\n",
    "    disabled=False,\n",
    "    selected=2,\n",
    "    button_style='',\n",
    ")\n",
    "\n",
    "interact(select_bands_hsv, c=buttons);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def threshold_hsv(val):\n",
    "    global threshold_value\n",
    "    threshold_value = val\n",
    "    \n",
    "    fig = plt.figure(figsize=(9, 9))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.set_title(\"Image after Thresholding\")\n",
    "\n",
    "    ax.imshow(image < val, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    \n",
    "    #plt.imshow(image > val, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #plt.show()\n",
    "    #plt.tight_layout()\n",
    "\n",
    "threshold_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=255,\n",
    "    step=1,\n",
    "    description='Threshold:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "interact(threshold_hsv, val=threshold_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove small holes\n",
    "\n",
    "There may be small specks in the above image. To remove these artefacts, click on the button below which removes shapes smaller than a certain size. This will clean up the image a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T14:57:01.024278Z",
     "start_time": "2018-02-19T14:57:00.863971Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "from skimage.morphology import disk\n",
    "\n",
    "def remove_small_objects(button):\n",
    "    from IPython import display as dsp\n",
    "    dsp.clear_output(wait=True)\n",
    "    display(button)\n",
    "    global image\n",
    "    global threshold_value\n",
    "    global image_cleaned\n",
    "    global closing_size\n",
    "    #image_cleaned = morphology.remove_small_objects((image < threshold_value), 50)\n",
    "    image_cleaned = morphology.closing(image < threshold_value, disk(closing_size))\n",
    "    fig = plt.figure(figsize=(9, 9))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.set_title(\"Cleaned Image\")\n",
    "    \n",
    "    # fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.imshow(image_cleaned, cmap=plt.\n",
    "              cm.gray, interpolation='nearest')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    #ax.set_adjustable('box-forced')\n",
    "\n",
    "\n",
    "button1 = widgets.Button(description=\"Click to clean image\")\n",
    "display(button1)\n",
    "button1.on_click(remove_small_objects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation\n",
    "\n",
    "Given the above image, we now find different connected clusters in the image, which we then label with different colours. Looking at the original images, we can expect three clusters: the land, the lake and the islands.\n",
    "\n",
    "Click on the button below to segment the image into these different classes.\n",
    "\n",
    "The left image shows the different classes. If everything has gone to plan, the right image should provide a nice outline of the lake.\n",
    "\n",
    "If you're happy with the outline, move to the next step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T14:57:04.267463Z",
     "start_time": "2018-02-19T14:57:03.904013Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def segment(button, save=False, image_index = None, silent=False):\n",
    "    from IPython import display as dsp\n",
    "    if not silent:\n",
    "        dsp.clear_output(wait=True)\n",
    "    if button is not None:\n",
    "        display(button)\n",
    "    global image\n",
    "    global image_rgb\n",
    "    global image_cleaned\n",
    "    global big_threshold\n",
    "    small_threshold = 10\n",
    "    segmentation = ndi.binary_fill_holes(image_cleaned)\n",
    "    labeled_image, n = ndi.label(segmentation)\n",
    "    sub = 0\n",
    "    for i in range(1,n+1):\n",
    "        s = (labeled_image==i).sum()\n",
    "        #print(\"Class %d - %d\" % (i,s))\n",
    "        if s > big_threshold:\n",
    "            idx = (labeled_image==i)\n",
    "            labeled_image[idx] = 0\n",
    "            sub += 1\n",
    "        if s < small_threshold:\n",
    "            idx = (labeled_image==i)\n",
    "            labeled_image[idx] = 0\n",
    "            sub += 1\n",
    "    \n",
    "    n -= sub\n",
    "    \n",
    "    image_label_overlay = label2rgb(labeled_image, image=image_cleaned)\n",
    "    \n",
    "    if save:\n",
    "        plt.clf()\n",
    "        plt.title(\"%s (%d objects detected)\" % (str(image_index), n))\n",
    "        plt.imshow(image_rgb, cmap=plt.cm.gray, interpolation='nearest')\n",
    "        plt.contour(labeled_image, [0.5], linewidths=1.2, colors='r')\n",
    "        fname = \"temp_{}.png\".format(image_index)\n",
    "        plt.savefig(fname)  \n",
    "        return n,fname\n",
    "    elif not silent:\n",
    "        fig = plt.figure(figsize=(12, 10))\n",
    "        ax1 = fig.add_subplot(1,2,2)\n",
    "\n",
    "        ax1.imshow(image_rgb, cmap=plt.cm.gray, interpolation='nearest')\n",
    "        ax1.contour(labeled_image, [0.5], linewidths=1.2, colors='r')\n",
    "        ax1.set_title(\"Contour Overlay\")\n",
    "\n",
    "        ax2 = fig.add_subplot(1,2,1)\n",
    "        ax2.imshow(labeled_image, interpolation='nearest')\n",
    "        ax2.set_title(\"Segmentation\")\n",
    "        #plt.show()\n",
    "        #plt.imshow(image_label_overlay, interpolation='nearest')\n",
    "        plt.tight_layout()\n",
    "        print(\"Number of objects detected: %d\" % (n))\n",
    "        \n",
    "    return n\n",
    "    \n",
    "    \n",
    "button2 = widgets.Button(description=\"Click to segment\")\n",
    "display(button2)\n",
    "button2.on_click(segment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Images\n",
    "\n",
    "Hopefully the settings that you have selected above provide good results. So let's try to apply these settings to some more images!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_to_image(filename, button):\n",
    "    global image_rgb\n",
    "    global image_hsv\n",
    "    global image\n",
    "    global image_cleaned\n",
    "    \n",
    "    image_rgb = io.imread(filename)\n",
    "    image_hsv = color.convert_colorspace(image_rgb, 'RGB', 'HSV')\n",
    "\n",
    "    if choice in ('Red','Green','Blue','All RGB Bands'):\n",
    "        image = _select_bands(image_rgb, choice)\n",
    "    else:\n",
    "        image = _select_bands(image_hsv, choice)\n",
    "\n",
    "    image_cleaned = morphology.closing(image < threshold_value, disk(10))\n",
    "    segment(None)\n",
    "    display(button)\n",
    "    \n",
    "\n",
    "def apply_image1(button):\n",
    "    apply_to_image('b3e7f584b.jpg', button)\n",
    "\n",
    "def apply_image2(button):\n",
    "    apply_to_image('667f66910.jpg', button)\n",
    "\n",
    "def apply_image4(button):\n",
    "    apply_to_image('7ceb4bba7.jpg',button)      \n",
    "    \n",
    "def apply_image3(button):\n",
    "    apply_to_image('37a908fa1.jpg',button)    \n",
    "    \n",
    "    \n",
    "\n",
    "button3 = widgets.Button(description=\"Segment Image 1\")\n",
    "display(button3)\n",
    "button3.on_click(apply_image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "button4 = widgets.Button(description=\"Segment Image 2\")\n",
    "display(button4)\n",
    "button4.on_click(apply_image2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Land Removal\n",
    "\n",
    "In images that have larges sections of land, our system will detect the land as a very large object. We know that we're actually looking for aeroplane debris that's a lot smaller, and so we can throw away these very large detected objects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_size(val):\n",
    "    global big_threshold\n",
    "    global image_cleaned\n",
    "    if val >= 500000:\n",
    "        return\n",
    "    big_threshold = val\n",
    "    image_cleaned = morphology.closing(image < threshold_value, disk(10))\n",
    "    segment(None)\n",
    "    #fig = plt.figure(figsize=(9, 9))\n",
    "    #ax = fig.add_subplot(1,1,1)\n",
    "    #ax.set_title(\"Image after Object Size Thresholding\")\n",
    "\n",
    "    #ax.imshow(image < val, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    \n",
    "    #plt.imshow(image > val, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #plt.show()\n",
    "    #plt.tight_layout()\n",
    "\n",
    "big_threshold_slider = widgets.IntSlider(\n",
    "    value=500001,\n",
    "    min=0,\n",
    "    max=500000,\n",
    "    step=25000,\n",
    "    description='Size Threshold:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "interact(threshold_size, val=big_threshold_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply to Multiple Images\n",
    "\n",
    "We have satellite images from a number of different areas of the ocean. So let's apply your colour choice and thresholding to these images too. Click on the button to generate an animation of these images. Be careful! What worked for the first image may not work for the rest of them! If you're happy with the result, move to the final step. Otherwise, go back and change your colour or threshold choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import animation  \n",
    "import matplotlib.image as mgimg\n",
    "import imageio\n",
    "from IPython.display import Image\n",
    "\n",
    "def apply_to_image_animation(filename, button, save_output=True, silent=False):\n",
    "    global image_rgb\n",
    "    global image_hsv\n",
    "    global image\n",
    "    global image_cleaned\n",
    "    global choice\n",
    "    global threshold_value\n",
    "    global big_threshold\n",
    "    global closing_size\n",
    "    \n",
    "    image_rgb = io.imread(filename)\n",
    "    image_hsv = color.convert_colorspace(image_rgb, 'RGB', 'HSV')\n",
    "\n",
    "    if choice in ('Red','Green','Blue','All RGB Bands'):\n",
    "        image = _select_bands(image_rgb, choice)\n",
    "    else:\n",
    "        image = _select_bands(image_hsv, choice)\n",
    "\n",
    "    image_cleaned = morphology.closing(image < threshold_value, disk(closing_size))\n",
    "    \n",
    "    if save_output:\n",
    "        (n,fname) = segment(None, save=True, image_index=filename)\n",
    "        display(button)\n",
    "        return (n, fname)\n",
    "    else:\n",
    "        n = segment(None, save=False, image_index=filename, silent=silent)\n",
    "        return n\n",
    "\n",
    "def build_animation(button):\n",
    "    \n",
    "    from IPython import display as dsp\n",
    "    dsp.clear_output(wait=True)\n",
    "    display(button)\n",
    "    \n",
    "    \n",
    "    progress = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=7 + 1,\n",
    "    step=1,\n",
    "    description='Building:',\n",
    "    bar_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    orientation='horizontal'\n",
    "    )\n",
    "    #display(progress)\n",
    "    \n",
    "    \n",
    "    #from IPython import display as dsp\n",
    "    #dsp.clear_output(wait=True)\n",
    "    #display(button)\n",
    "        \n",
    "    # segment_image(1984)\n",
    "    #from IPython import display as dsp\n",
    "    #dsp.clear_output(wait=True)\n",
    "    #interact(segment_image, year=year_slider)\n",
    "    files = []\n",
    "    sum_objects = 0\n",
    "    sum_pictures = 0\n",
    "    images= [\"1fbc5de57.jpg\",\"37a908fa1.jpg\",\"7ceb4bba7.jpg\",\"34b2f95c3.jpg\",\"667f66910.jpg\",\"b3e7f584b.jpg\",\"ba78ed889.jpg\"]\n",
    "    for j,i in enumerate(images):\n",
    "        print(\"Processing image %d/%d.\" % (j+1, len(images)))\n",
    "        n, fname = apply_to_image_animation(i, button)\n",
    "        files.append(fname)\n",
    "        progress.value += 1\n",
    "        sum_objects += n\n",
    "        sum_pictures += (n > 0)\n",
    "\n",
    "    \n",
    "    print(\"Merging Images...\")\n",
    "    imageio.mimsave('temp.gif', [imageio.imread(f) for f in files], 'GIF', duration=1)\n",
    "    print(\"Done\")\n",
    "    progress.value += 1\n",
    "    display(Image(filename='temp.gif', width=750, height=500))\n",
    "    #ani = animation.ArtistAnimation(fig, ims, interval=1000, blit=True, repeat_delay=1000)\n",
    "    #plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "button3 = widgets.Button(description=\"Build Animation\")\n",
    "display(button3)\n",
    "\n",
    "button3.on_click(build_animation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy on unseen images\n",
    "\n",
    "Now that we believe our system is working properly, we will run it on 30 areas where we have taken satellite images. Click the button below to run your code on all the images from the search party.\n",
    "\n",
    "Be patient while the system processes all the images based on the method and parameters that you have chosen above. This could take up to 3 minutes to finish. Once it has completed, feel free to go back and change your paramters to see whether you can do better when helping the search party."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = open('test-images/testing.txt')\n",
    "testing_lines = f.readlines()\n",
    "\n",
    "def finaltest(button):\n",
    "    global threshold_value\n",
    "    global big_threshold\n",
    "    from IPython import display as dsp\n",
    "    dsp.clear_output(wait=True)\n",
    "    print(\"File\\t\\t\\tObjectsDetected\\t\\tActualObjects\\tCheckImage\\tCorrectObjects\")\n",
    "    i = 0\n",
    "    n_should_check = 0\n",
    "    \n",
    "    n_tp = 0\n",
    "    n_fp = 0\n",
    "    n_tn = 0\n",
    "    n_fn = 0\n",
    "    \n",
    "    n_total_objects     = 0\n",
    "    n_missed_objects    = 0\n",
    "    n_found_objects     = 0\n",
    "    n_imaginary_objects = 0\n",
    "    max = 30\n",
    "    for t in testing_lines:            \n",
    "        l = t.split(',')\n",
    "        filename,numobjects = (l[0],int(l[1]))\n",
    "        n = apply_to_image_animation(\"test-images/\" + filename, None, save_output=False, silent=True)\n",
    "        shouldcheck = \"No\"\n",
    "        if n > 0 and numobjects > 0:\n",
    "            # Image should be checked, and is (correct) - TP\n",
    "            n_tp += 1\n",
    "            n_should_check += 1\n",
    "            shouldcheck = \"Yes\"\n",
    "        elif n > 0 and numobjects == 0:\n",
    "            # Image shouldn't be checked, but is - FP\n",
    "            n_fp += 1\n",
    "            n_should_check += 1\n",
    "            shouldcheck = \"Yes\"\n",
    "        elif n == 0 and numobjects > 0:\n",
    "            # Image won't be checkede, but should - FN\n",
    "            n_fn += 1\n",
    "            shouldcheck = \"No\"\n",
    "        elif n == 0 and numobjects == 0:\n",
    "            # Image shouldn't be checked and isn't - TN\n",
    "            n_tn += 1\n",
    "            shouldcheck = \"No\"\n",
    "        \n",
    "        n_total_objects += numobjects\n",
    "        if   n == numobjects:\n",
    "            correct = \"Yes\"\n",
    "            n_found_objects += n\n",
    "        elif n > numobjects:\n",
    "            correct = \"No\"\n",
    "            n_found_objects += numobjects\n",
    "            n_imaginary_objects += (n-numobjects)\n",
    "        elif n < numobjects:\n",
    "            correct = \"No\"\n",
    "            n_found_objects += n\n",
    "            n_missed_objects += numobjects - n\n",
    "            \n",
    "            \n",
    "        print(\"[%2d/%d] %s\\t%d\\t\\t\\t%d\\t\\t%s\\t\\t%s\" % (i+1,max,filename, n, numobjects,shouldcheck,correct))\n",
    "        i +=1\n",
    "        if i == max:\n",
    "            break\n",
    "        \n",
    "    acc = 0.3\n",
    "    print(\"\\n\\nYou told search parties to check %2d areas and skip %2d areas.\" % (n_tp + n_fp, n_tn + n_fn))\n",
    "    print(\"✓\\tSearch parties correctly checked %2d areas that actually had objects (correct).\" % (n_tp))\n",
    "    print(\"✓\\tSearch parties correctly skipped %2d areas that did not have objects (saved time).\" % (n_tn))\n",
    "    print(\"✗\\tSearch parties incorrectly checked %2d areas that did not have objects (wasted time).\" % (n_fp))\n",
    "    print(\"✗\\tSearch parties incorrectly skipped %2d areas that actually had objects (potentially missed survivors).\" % (n_fp))\n",
    "    print(\"You correctly classified %3.2f%% of the areas.\" % ((n_tp+n_tn)/(n_tp+n_fp+n_tn+n_fn)*100))\n",
    "    \n",
    "    print(\"\\n✓\\tYou correctly found %d objects out of %d.\" % (n_found_objects,n_total_objects))\n",
    "    print(\"✗\\tYou missed %d objects.\" % (n_missed_objects))\n",
    "    print(\"✗\\tYou identified %d objects that weren't there.\" % (n_imaginary_objects)) \n",
    "    \n",
    "    print(\"\\nYou used the following settings:\\n\\tChannel: %s, Threshold: %d, ObjectSizeThreshold: %d\" % (choice,threshold_value,big_threshold))\n",
    "    display(button_test)\n",
    "\n",
    "    \n",
    "button_test = widgets.Button(description=\"Test on large dataset\")\n",
    "display(button_test)\n",
    "button_test.on_click(finaltest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congrats!\n",
    "\n",
    "You've just used machine learning to building an object detection model on satellite imagery that can be used to speed up the search for the survivors! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "HTML('''\n",
    "<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "You can toggle the code on and off by clicking <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
